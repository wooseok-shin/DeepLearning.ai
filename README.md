# Coursera DeepLearning.ai
Coursera Deep Learning Specialization(by Andrew Ng) 강의 정리


## Course 1. Neural Networks and Deep Learning

Week2: [Neural Networks Basics](https://github.com/wooseok-shin/DeepLearning.ai/tree/master/1.%20Neural%20Networks%20and%20Deep%20Learning/week2)
* Logistic Regression(로지스틱 회귀)
* Logistic Regression Cost Function(로지스틱 회귀 비용함수)
* Gradient Descent(경사하강법)
* Computation Graph & 미분
* Logistic Regression에서의 Gradient Descent


Week3: [Shallow Neural Networks](https://github.com/wooseok-shin/DeepLearning.ai/tree/master/1.%20Neural%20Networks%20and%20Deep%20Learning/week3)
* Neural network Representation and Vectorization
* Activation Function(활성화 함수)
* non-linear Activation Function를 사용하는 이유
* Activation Function(활성화 함수) 미분  
* Weight Random Initialization(가중치 초기화)


Week4: [Deep Neural Networks](https://github.com/wooseok-shin/DeepLearning.ai/tree/master/1.%20Neural%20Networks%20and%20Deep%20Learning/week4)
* Forward Propagation  
* Getting your Matrix dimension right  
* Why deep Representations? (깊은 신경망이 더 많은 특징을 잡아내는 이유, 직관적으로)  
* Parameters vs HyperParameters  
* Forward and Backward propagation  

