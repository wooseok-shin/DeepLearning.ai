## ML Strategy(1)

### 학습목표

* Understand what multi-task learning and transfer learning are
* Recognize bias, variance and data-mismatch by looking at the performances of your algorithm on train/dev/test sets

  
  
## Carrying Out Error Analysis

- 오차 분석을 통해 알고리즘이 범하고 있는 실수를 직접 파악하여 오차를 줄이는 것에 대한 비용을 알아 볼 수 있다.
	- 또한, 이 과정에서 새로운 오류가 어떤 것들이 있는지 알 수 있다. Ex)인스타그램 필터  
	
예를들어, 고양이 분류모델이 있을 때 Dev(Test)set에 대해 모델이 잘못 예측한 데이터가 100개라 하자.  
	1) 그 중 개 사진이 5개 --> 개의 특징을 보정해주어도 성능은 0.5%정도밖에 오르지 않는다.  
	2) 그 중 개 사진이 50개 --> 개의 특징을 보정해주면 성능은 5%정도 개선을 생각할 수 있다.  

- 만약 성능개선에 여러개의 아이디어가 있을 경우
|Image|개 사진|흐릿한 사진|고양이과(표범,치타)|과한 필터|Comments|
|------|---|---|---|---|---|
|1|Check|.|.|.|Black Dog|
|2|.|Check|Check|.|비가 와서 흐릿|
|3|.|.|Check|.|.|
|...|Check|.|.|.|.|
|% of Total|8%|53%|46%|12%|.|

모델이 개 사진, 흐릿한 사진, 큰 고양이과 동물, 또는 과한 필터 등을 잘못 분류했을 경우  
위와 같이 각 이미지에 대해 여러 아이디어를 표로 만들고 해당하는지 Check를 한다.    
위의 결과는 개 사진이 8%, 흐릿한 사진이 53%, 고양이과는 46%, 과한 필터는 12%이다.  
즉, 흐릿한 사진이나 고양이과에 대한 Error가 큰 것을 볼 수 있다.

- 따라서, 모델이 잘못 분류 한 예시들에서 비중을 가장 많이 차지하는 부분을 찾아서 해당 오류를 고치는 것이 가장 효율이 좋다.  


  
  
## Cleaning Up Incorrectly Labelled Data

- 잘못 라벨링 된 데이터를 처리하는 방법
- Train Set:
	- Train set은 무작위 오차에 대해 다소 둔감하다. 잘못 라벨링된 데이터의 Train error가 무작위 오차와 크게 차이 나지 않을 경우는 고치지 않아도 된다.  
	- 하지만 무작위 오차가 아닌 시스템적 오류(Ex.모든 흰색 개를 고양이로 잘못 라벨링한 경우)는 문제가 될 수 있다.  
	
- Dev, Test Set:
	- 오차 분석시 잘못 라벨링된 오차의 비율을 구하고, 전체 오차에서 얼마큼 차지하는지를 살펴보고 결정  
	- Dev, Test set의 분포가 같아야하기 때문에 라벨을 고칠 경우 동시에 고쳐야한다.  

|Image|개 사진|흐릿한 사진|고양이과(표범,치타)|과한 필터|잘못라벨링|Comments|
|------|---|---|---|---|---|---|
|1|Check|.|.|.|.|Black Dog|
|2|.|Check|Check|.|Check|배경에 작은 고양이가 있음|
|3|.|.|Check|.|.|.|
|...|Check|.|.|.|Check|고양이 그림이 있음|
|% of Total|8%|53%|46%|12%|6%|.|

- 위의 표에서 잘못라벨링된 경우가 6%이다. 상황에 따라 그대로 둘수도 있고 고칠수도 있다.  
  
  

- 새로운 머신러닝 모델을 적용할 때, 시스템을 빨리 만든 후 다시 검토하는 방식이 좋다
	- 훈련, 개발 및 시험 세트를 만들고 학습 목표를 정합니다.
	- 빠르게 시스템을 구성합니다. 즉, 모델링을 합니다.
	- 훈련 세트를 통해 모델을 학습 시키고, 개발 및 시험 세트로 평가를 합니다.
	- 편향-분산 분석 및 오차 분석을 통해 모델의 성능을 향상 시킵니다.