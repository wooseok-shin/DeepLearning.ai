## ML Strategy(2)

### 학습목표

* Understand what multi-task learning and transfer learning are
* Recognize bias, variance and data-mismatch by looking at the performances of your algorithm on train/dev/test sets

  
  
## Carrying Out Error Analysis

- 오차 분석을 통해 알고리즘이 범하고 있는 실수를 직접 파악하여 오차를 줄이는 것에 대한 비용을 알아 볼 수 있다.
	- 또한, 이 과정에서 새로운 오류가 어떤 것들이 있는지 알 수 있다. Ex)인스타그램 필터  
	
예를들어, 고양이 분류모델이 있을 때 Dev(Test)set에 대해 모델이 잘못 예측한 데이터가 100개라 하자.  
	1) 그 중 개 사진이 5개 --> 개의 특징을 보정해주어도 성능은 0.5%정도밖에 오르지 않는다.  
	2) 그 중 개 사진이 50개 --> 개의 특징을 보정해주면 성능은 5%정도 개선을 생각할 수 있다.  

- 만약 성능개선에 여러개의 아이디어가 있을 경우  

|Image|개 사진|흐릿한 사진|고양이과(표범,치타)|과한 필터|Comments|
|------|---|---|---|---|---|
|1|Check|.|.|.|Black Dog|
|2|.|Check|Check|.|비가 와서 흐릿|
|3|.|.|Check|.|.|
|...|Check|.|.|.|.|
|% of Total|8%|53%|46%|12%|.|

모델이 개 사진, 흐릿한 사진, 큰 고양이과 동물, 또는 과한 필터 등을 잘못 분류했을 경우  
위와 같이 각 이미지에 대해 여러 아이디어를 표로 만들고 해당하는지 Check를 한다.    
위의 결과는 개 사진이 8%, 흐릿한 사진이 53%, 고양이과는 46%, 과한 필터는 12%이다.  
즉, 흐릿한 사진이나 고양이과에 대한 Error가 큰 것을 볼 수 있다.

- 따라서, 모델이 잘못 분류 한 예시들에서 비중을 가장 많이 차지하는 부분을 찾아서 해당 오류를 고치는 것이 가장 효율이 좋다.  


  
  
## Cleaning Up Incorrectly Labelled Data

- 잘못 라벨링 된 데이터를 처리하는 방법
- Train Set:
	- Train set은 무작위 오차에 대해 다소 둔감하다. 잘못 라벨링된 데이터의 Train error가 무작위 오차와 크게 차이 나지 않을 경우는 고치지 않아도 된다.  
	- 하지만 무작위 오차가 아닌 시스템적 오류(Ex.모든 흰색 개를 고양이로 잘못 라벨링한 경우)는 문제가 될 수 있다.  
	
- Dev, Test Set:
	- 오차 분석시 잘못 라벨링된 오차의 비율을 구하고, 전체 오차에서 얼마큼 차지하는지를 살펴보고 결정  
	- Dev, Test set의 분포가 같아야하기 때문에 라벨을 고칠 경우 동시에 고쳐야한다.  

|Image|개 사진|흐릿한 사진|고양이과(표범,치타)|과한 필터|잘못라벨링|Comments|
|------|---|---|---|---|---|---|
|1|Check|.|.|.|.|Black Dog|
|2|.|Check|Check|.|Check|배경에 작은 고양이가 있음|
|3|.|.|Check|.|.|.|
|...|Check|.|.|.|Check|고양이 그림이 있음|
|% of Total|8%|53%|46%|12%|6%|.|

- 위의 표에서 잘못라벨링된 경우가 6%이다. 상황에 따라 그대로 둘수도 있고 고칠수도 있다.  
  
  

- 새로운 머신러닝 모델을 적용할 때, 시스템을 빨리 만든 후 다시 검토하는 방식이 좋다
	- 훈련, 개발 및 시험 세트를 만들고 학습 목표를 정한다.
	- 빠르게 시스템을 구성. 즉, 모델링을 한다.
	- 훈련 세트를 통해 모델을 학습 시키고, 개발 및 시험 세트로 평가한다.
	- 편향-분산 분석 및 오차 분석을 통해 모델의 성능을 향상 시킨다.
	
	
  
  
## Training and Testing On Different Distributions

예를들어 Cat 분류 어플을 학습시킨다고 할 때, 웹 페이저에서 모은 선명한 사진 200,000장과 실제 사용자들이 찍은 흐릿한 사진 10,000장이 있다고 하자.
	- Option 1) 200,000장 + 10,000장을 합친 후 무작위로 Shuffle 한다. 그 후 Train,Dev,Test로 나누어 205,000장, 2500장, 2500장으로 나눌 수 있을 것이다.  
		- 단점: Dev set 2,500장 중 2500* (200000/210000)=2381, 즉 2,381장이 웹에서 온 선명한 사진으로 구성되어 있다. 이는 Dev set이 실제로는 좋지 않은 모델을 좋은 모델로 잘못 평가할 수 있다.  
		
	- Option 2) 200,000장 + 5,000장을 Train set으로, Dev/Test set은 모두 모바일 앱에서 얻어진 사진으로 사용한다.  
		- 장점: 실제로 원하는 것을 목표로 할 수 있다.(실제 사용될 흐릿한 사진만을 평가하는 것이므로)
		- 단점: Train과 Dev/Test의 분포가 다르다. --> 하지만 장기적으로는 Option2가 더 좋은 성능을 낸다.
		
	
## Bias and Variance With Mismatched Data distribusions

위의 Cat 분류 어플을 학습시킨 결과 다음과 같은 결과가 나왔다고 하자.  

|Bayes Error|0%|
|---|---|
|Train Error|1%|
|Dev Error|10%|

- 이는 Train Error와 Dev Error의 차이가 크기 때문에 Variance 문제로 생각할 수 있다.
- 하지만, 위의 학습 시에 Train과 Dev의 분포가 다르기 때문에 Train/Dev의 분포 문제로 발생한 것일 수 있다.(Dev set이 맞추기 더 어려운 사진일 경우)

- 따라서, 둘 중 어떤 것이 Error에 영향을 미치는지 알아보기 위해 Train set의 일부분을 떼어 Train-Dev set으로 만든다.(학습에 사용하지 않음)

Case1) 

|Bayes Error|0%|
|---|---|
|Train Error|1%|
|Train-Dev Error|9%|
|Dev Error|10%|

같은 분포의 Train-Dev set에서도 Dev set과 비슷한 결과를 나타내므로 이는 **Variance** 문제로 볼 수 있다.  

Case2)

|Bayes Error|0%|
|---|---|
|Train Error|1%|
|Train-Dev Error|1.5%|
|Dev Error|10%|

학습에 사용되지 않은 Train-Dev set에서는 좋은 성능을 보이나 Dev에서는 낮은 성능을 보이므로 **Data-Mismatched** 문제로 볼 수 있다.

Case3)

|Bayes Error|0%|
|---|---|
|Train Error|10%|
|Train-Dev Error|11%|
|Dev Error|20%|

Avoidable Bias & Data-Mismatched 문제를 동시에 가지고 있는 것으로 볼 수있다.

- 종합적으로, 아래의 그림을 참고하여 어떤 문제가 있는지를 확인할 수 있음

<img width="722" alt="train-dev" src="https://user-images.githubusercontent.com/46666862/72236807-a6486280-361b-11ea-97c8-731ae68e2f54.png">  


  
  
## Addressiong Data Mismatch

- 데이터 분포의 불일치 문제가 생겼을 때 시도해볼만한 방법  
	- 1. Error Analysis를 통해 Train과 Dev Set 두 분포가 어떻게 다른지를 알아보기 
		- Example) 음성인식에서 자동차안에서 음성비서를 훈련시킬 때 Train set은 일반적인 깨끗한 음성, Dev set은 실제 자동차에서 발생하는 음성일 수 있다. 이 때 Dev set은 자동차의 noise가 섞여있을 수 있다.
	- 2. Dev set과 비슷한 Train Set을 더 얻기
		- 인공 데이터 합성을 통해 얻을 수 있다.  
		- Example) Train set(깨끗한 음성, 1만 시간)과 자동차 Noise(1시간)를 합성하여 노이즈가 포함된 Train set을 구성할 수 있다. 단, 1시간의 노이즈가 만 번 반복되는 것이므로 1시간의 노이즈에 과하게 피팅될 수 있으므로 주의해야 한다.  
		
	

  
## Transfer Learning

- 전이학습의 방법은 기존 학습된 모델에서 마지막 층을 제거한 후, 분류 하고자 하는 문제에 적합한 층을 연결시켜주고 학습하게 된다.  
	- 내가 풀고자 하는 문제의 데이터가 많을 경우, 모든 층을 재훈련한다.  
	- 내가 풀고자 하는 문제의 데이터가 거의 없을 경우, 새로 추가한 마지막 층만 학습한다.  

- 전이학습의 장점은 기존에 학습된 지식을 데이터가 적은 문제에 적용시킬수 있다는 것이다. 이미지 인식 같은 경우, Low-level 특징, 즉, 윤곽이나 물체의 일부분을 탐지하는 기존 모델을 방사선의학의 이미지에 적용할 수 있다.

- 전이학습은 아래의 상황에서 많이 쓰인다.
	- 전이 가능한 문제의 데이터(기존 이미지 인식에 사용되는 데이터)는 많은데 전이 하려고 하는 문제의 데이터가 적을 때
	- 입력 데이터가 같고, Low-level 특성이 문제를 해결하는데 도움이 될 때  
	
	

  
## Multi-task Learning

- 다중 작업 학습은 하나의 신경망이 여러작업을 동시에 할 수 있도록 학습하는 것이다.
	- 이미지 다중 분류 학습은 신경망 초기 특성들은 여러 물체에서 공유가 가능하기 때문에, 하나의 신경망으로 학습시키는 것이 여러 신경망을 개별 학습시키는 것 보다 효율적이다.

- 다중 작업 학습은 아래의 상황에서 많이 쓰인다.
	- 여러 문제들의 하나의 저레벨 특성을 공유할 때
	- 데이터가 비슷할 때 (예를들면, 자율주행 이미지 인식에서 표지판을 인식하는 특성과 가로등을 인식하는 특성이 서로 도움을 받을 수 있다)
	- 거대한 작업 세트들을 하나의 큰 신경망으로 한번에 학습 시키려고 할 때

  
  
  
## What is end-to-end Deep Learning?

- end-to-end 딥러닝은 자료처리 시스템이나나 학습시스템에서 여러 단계의 필요한 처리과정을 한번에 처리한다. 즉, 데이터만 입력하고 원하는 목적을 학습시키는 것이다.  
- 이는 기존의 처리 파이프라인을 간단하게 만들 수 있다. 다만, end-to-end 딥러닝은 엄청나게 많은 양의 데이터가 필요하다.
- 그러나 실제로 몇몇 Application에서는 여러 단계로 나누어 학습 시키는 것이 효율적일 때도 있다.  
	- 예를들어, 회사 출입을 얼굴인식으로 한다고 했을 때 사원인지를 한 번에 처리하는 것보다 단계를 나누는 것이 더 좋다.  
		- Step1. 이미지 중 얼굴을 찾고 확대시키기
		- Step2. 확대된 얼굴을 보고 기존 등록된 얼굴과 같은지를 판단하기
	- 이렇게 단계를 나누면 사용할 수 있는 (X,Y) 데이터 쌍이 많아지고 풀고 싶은 문제도 간단해진다.
	
- 따라서, 순수 end-to-end 보다는 문제를 쪼개서 해결하는 것이 좋을 수 있다.

  
  
## Whether to use end-to-end Deep Learing

- end-to-end 딥러닝의 장단점
	- 장점
		- 데이터만을 이용. 즉, 사람의 선입견에 영향을 덜 받는다.
		- 사람이 설계하는 중간 요소를 줄일 수 있다.
	- 단점
		- 방대한 양의 데이터가 필요합니다.
		- 사람의 손으로 만들어진 유용할 수 있는 중간 요소를 완전 배제한다. 이는 데이터가 적을 때는 효율적으로 작동하는 특정 지식을 사용할 수 없다.

- 따라서, end-to-end 딥러닝을 사용하기전에 항상 어떤 작업을 하려고 하는지, 특히 지도학습에서 X와 Y 를 어떻게 연관지을 것인지를 생각해야한다. 또한, 학습하기 위한 데이터가 충분한지도 고려해야한다.

  
  
  
  
  
## Assignment 오답

- 8번, Dev set error 분석 결과 Error를 일으키는 여러 원인 중 foggy 이미지의 비중이 가장 높다고 할 때 foggy 이미지를 추가해서 문제를 해결해야 하는가?
	- 가장 큰 오차의 원인을 고려하는 것이 좋긴 하지만 유일한 고려 사항은 아니다. 그리고 오히려 추가 안개 데이터를 얻는 것이 더 큰 비용이 들수도 있기 때문이다.
	
- 10번, 안개 이미지 합성으로 옳은 것은 --> 합성된 안개가 사람의 눈에 사실적으로 보이면 실제 안개 이미지의 분포에 포함시킬 수 있을 것이다.(사람의 시각 처리가 문제 해결에 더 정확하므로)

- 13번, 차 외부에 음성 인식 시스템 --> 기존 자율주행(이미지 처리) 모델과는 Tranfer Learning이나 Multi-task Learning과 연관이 없다. --> 새로운 데이터와 모델을 만들어야 한다.  


